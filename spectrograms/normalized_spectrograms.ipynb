{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH_0 = \"../birdclef-2022-data\"\n",
    "PATH_1 = \"birdclef-2022-data\"\n",
    "train = pd.read_csv(f\"{PATH_1}/train_metadata.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "AUDIO_PATH = f\"{PATH_1}/train_audio\"\n",
    "IMAGE_PATH = f\"{PATH_1}/train_images/\"\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])\n",
    "NUM_WORKERS = 4\n",
    "CLASSES = sorted(os.listdir(AUDIO_PATH))\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "class AudioParams:\n",
    "    \"\"\"\n",
    "    Parameters used for the audio data\n",
    "    \"\"\"\n",
    "    sr = 32000\n",
    "    duration = 5\n",
    "    length = sr * duration\n",
    "    # Melspectrogram\n",
    "    n_mels = 224\n",
    "    fmin = 20\n",
    "    fmax = 16000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crop_or_pad(y):\n",
    "    \"\"\"\n",
    "    Crops an array to a chosen length\n",
    "    Arguments:\n",
    "        y {1D np array} -- Array to crop\n",
    "        length {int} -- Length of the crop\n",
    "        sr {int} -- Sampling rate\n",
    "    Keyword Arguments:\n",
    "        train {bool} -- Whether we are at train time. If so, crop randomly, else return the beginning of y (default: {True})\n",
    "        probs {None or numpy array} -- Probabilities to use to chose where to crop (default: {None})\n",
    "    Returns:\n",
    "        1D np array -- Cropped array\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    length = len(y)\n",
    "    z = []\n",
    "    for _ in range(math.ceil(len(y) / AudioParams.length)):\n",
    "        if length <= AudioParams.length:\n",
    "            z.append(np.concatenate([y[start:], np.zeros(AudioParams.length - length)]).astype(np.float32))\n",
    "        else:\n",
    "            z.append(y[start: start + AudioParams.length].astype(np.float32))\n",
    "            length -= AudioParams.length\n",
    "            start += AudioParams.length\n",
    "\n",
    "    return z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_melspec(y, params):\n",
    "    \"\"\"\n",
    "    Computes a mel-spectrogram and puts it at decibel scale\n",
    "    Arguments:\n",
    "        y {np array} -- signal\n",
    "        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n",
    "    Returns:\n",
    "        np array -- Mel-spectrogram\n",
    "    \"\"\"\n",
    "    melspec = librosa.feature.melspectrogram(\n",
    "        y=y, sr=params.sr, n_mels=params.n_mels, fmin=params.fmin, fmax=params.fmax,\n",
    "    )\n",
    "\n",
    "    melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "    return melspec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Converts a one channel array to a 3 channel one in [0, 255]\n",
    "    Arguments:\n",
    "        X {numpy array [H x W]} -- 2D array to convert\n",
    "    Keyword Arguments:\n",
    "        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n",
    "        mean {None or np array} -- Mean for normalization (default: {None})\n",
    "        std {None or np array} -- Std for normalization (default: {None})\n",
    "    Returns:\n",
    "        numpy array [3 x H x W] -- RGB numpy array\n",
    "    \"\"\"\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5 sec cropped\n",
    "audio_name = f\"{PATH_1}/train_audio/afrsil1/XC125458.ogg\"\n",
    "\n",
    "#path = train['file_path'][0]\n",
    "y, sr = sf.read(audio_name, always_2d=True)\n",
    "print(len(y)/sr)\n",
    "y = np.mean(y, 1)\n",
    "y = crop_or_pad(y)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for index, element in enumerate(y):\n",
    "    ax = plt.subplot(2, 2, index + 1)\n",
    "    X = compute_melspec(element, AudioParams)\n",
    "    X = mono_to_color(X)\n",
    "    X = X.astype(np.uint8)\n",
    "    plt.imshow(X)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Audio_to_Images(path, save_path, params):\n",
    "    y, sr = sf.read(path, always_2d=True)\n",
    "    y = np.mean(y, 1) # there is (X, 2) array\n",
    "    y = crop_or_pad(y)\n",
    "    for index, img in enumerate(y):\n",
    "        image = compute_melspec(img, params)\n",
    "        image = mono_to_color(image)\n",
    "        image = image.astype(np.uint8)\n",
    "        np.save(save_path + f\"_{index}\", image)\n",
    "\n",
    "def save_(path):\n",
    "    save_path = IMAGE_PATH + \"/\".join(path.split('/')[-2:])\n",
    "    save_path = save_path[:-4]\n",
    "    Audio_to_Images(path, save_path, AudioParams)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "paths = AUDIO_PATH + '/' + train['filename']\n",
    "paths = paths.values\n",
    "print(paths)\n",
    "save_(paths[0])\n",
    "\n",
    "path_name = f\"{PATH_1}/train_images/afrsil1/XC125458_0.npy\"\n",
    "spec = np.load(path_name)\n",
    "plt.imshow(spec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_and_generate_specs():\n",
    "     NUM_WORKERS = 14\n",
    "     _ = Parallel(n_jobs=NUM_WORKERS)(delayed(save_)(AUDIO_PATH) for AUDIO_PATH in tqdm(paths))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#save_and_generate_specs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}