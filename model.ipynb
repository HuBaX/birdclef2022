{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import KMNIST\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "\tdef __init__(self, numChannels, classes):\n",
    "\t\t# call the parent constructor\n",
    "\t\tsuper(LeNet, self).__init__()\n",
    "\n",
    "\t\t# initialize first set of CONV => RELU => POOL layers\n",
    "\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu1 = ReLU()\n",
    "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\t# initialize second set of CONV => RELU => POOL layers\n",
    "\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu2 = ReLU()\n",
    "\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "\t\t# initialize first (and only) set of FC => RELU layers\n",
    "\t\tself.fc1 = Linear(in_features=800, out_features=500)\n",
    "\t\tself.relu3 = ReLU()\n",
    "\n",
    "\t\t# initialize our softmax classifier\n",
    "\t\tself.fc2 = Linear(in_features=500, out_features=classes)\n",
    "\t\tself.logSoftmax = LogSoftmax(dim=1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "\t\tx = flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu3(x)\n",
    "\t\t# pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "\t\tx = self.fc2(x)\n",
    "\t\toutput = self.logSoftmax(x)\n",
    "\t\t# return the output predictions\n",
    "\t\treturn output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, annotations_file, img_dir):\n",
    "\t\tself.img_labels = pd.read_csv(annotations_file)\n",
    "\t\tself.img_dir = img_dir\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.img_labels)\n",
    "\n",
    "\tdef __get_classes__(self):\n",
    "\t\treturn len(self.img_labels['label'].unique())\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "\t\timage = np.load(img_path)\n",
    "\t\tlabel = self.img_labels.iloc[idx, 1]\n",
    "\t\treturn image, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "AUDIO_PATH = '../birdclef-2022-data/train_audio'\n",
    "IMAGE_PATH = '../birdclef-2022-data/train_images/'\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afrsil1/XC125458_0.npy\n",
      "                file_name    label\n",
      "0  afrsil1/XC125458_0.npy  afrsil1\n",
      "1  afrsil1/XC125458_1.npy  afrsil1\n",
      "2  afrsil1/XC125458_2.npy  afrsil1\n",
      "3  afrsil1/XC175522_0.npy  afrsil1\n",
      "4  afrsil1/XC175522_1.npy  afrsil1\n"
     ]
    }
   ],
   "source": [
    "# collect data about data structure\n",
    "all_data = []\n",
    "for primary_label in os.listdir(IMAGE_PATH):\n",
    "    all_data += [primary_label + '/' + x for x in os.listdir(IMAGE_PATH + primary_label)]\n",
    "\n",
    "base_data = {'file_name': [], 'label': []}\n",
    "for item in all_data:\n",
    "    base_data['file_name'].append(item)\n",
    "    base_data['label'].append(item.split('/')[0])\n",
    "\n",
    "results = pd.DataFrame(base_data, columns = ['file_name', 'label'])\n",
    "print(results.head())\n",
    "results.to_csv(\"annotated_data.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len training: 108632, len test: 36211\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "numTrainSamples = round(len(all_data) * TRAIN_SPLIT)\n",
    "numValSamples = round(len(all_data) * VAL_SPLIT)\n",
    "\n",
    "data_set = CustomDataset(\"annotated_data.csv\", IMAGE_PATH)\n",
    "\n",
    "(trainData, valData) = random_split(data_set, [numTrainSamples, numValSamples],generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(f\"len training: {len(trainData)}, len test: {len(valData)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainData, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
    "\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the LeNet model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomDataset' object has no attribute '__get_classes__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [70]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# initialize the LeNet model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[INFO] initializing the LeNet model...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m LeNet(\n\u001B[0;32m      4\u001B[0m \tnumChannels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m----> 5\u001B[0m \tclasses\u001B[38;5;241m=\u001B[39m(\u001B[43mdata_set\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_classes__\u001B[49m())\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# initialize our optimizer and loss function\u001B[39;00m\n\u001B[0;32m      7\u001B[0m opt \u001B[38;5;241m=\u001B[39m Adam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mINIT_LR)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CustomDataset' object has no attribute '__get_classes__'"
     ]
    }
   ],
   "source": [
    "# initialize the LeNet model\n",
    "print(\"[INFO] initializing the LeNet model...\")\n",
    "model = LeNet(\n",
    "\tnumChannels=3,\n",
    "\tclasses=(data_set.__get_classes__()).to(device))\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.NLLLoss()\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "# loop over our epochs\n",
    "for e in range(0, EPOCHS):\n",
    "\t# set the model in training mode\n",
    "\tmodel.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\t# initialize the number of correct predictions in the training\n",
    "\t# and validation step\n",
    "\ttrainCorrect = 0\n",
    "\tvalCorrect = 0\n",
    "\t# loop over the training set\n",
    "\tfor (x, y) in trainDataLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = model(x)\n",
    "\t\tloss = lossFn(pred, y)\n",
    "\t\t# zero out the gradients, perform the backpropagation step,\n",
    "\t\t# and update the weights\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\t# add the loss to the total training loss so far and\n",
    "\t\t# calculate the number of correct predictions\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\ttrainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "\t# switch off autograd for evaluation\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in valDataLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = model(x)\n",
    "\t\t\ttotalValLoss += lossFn(pred, y)\n",
    "\t\t\t# calculate the number of correct predictions\n",
    "\t\t\tvalCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_name = '../birdclef-2022-data/train_images/afrsil1/XC125458_0.npy'\n",
    "spec = np.load(path_name)\n",
    "\n",
    "print(spec.shape)\n",
    "print(np.array_equal(spec[0], spec[1]))\n",
    "print(spec)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}