{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch.cuda\n",
    "from flash.image import ImageClassificationData, ImageClassifier\n",
    "from pytorch_lightning import seed_everything\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torchmetrics\n",
    "import flash\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_PATH = '../../../birdclef-2022-data'\n",
    "AUDIO_PATH = '../../../birdclef-2022-data/train_audio'\n",
    "IMAGE_PATH = '../../../birdclef-2022-data/train_images/'\n",
    "All_BUT_LAST = True\n",
    "ONLY_FIRST = False\n",
    "SEED = 42\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, x, y, img_dir):\n",
    "\t\tself.x = x\n",
    "\t\tself.y = y\n",
    "\t\tself.img_dir = img_dir\n",
    "\t\tself.classes = np.unique(self.y)\n",
    "\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.x)\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = os.path.join(self.img_dir, self.x[idx])\n",
    "\t\timage = np.load(img_path)\n",
    "\t\tlabel = self.y[idx]\n",
    "\t\treturn image, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# collect data about data structure\n",
    "def create_first_clip():\n",
    "    all_data = []\n",
    "    for primary_label in os.listdir(IMAGE_PATH):\n",
    "        all_data += [primary_label + '/' +\n",
    "                        x for x in os.listdir(IMAGE_PATH + primary_label) if x.endswith('_0.npy')\n",
    "                        ]\n",
    "    all_data += ['maupar/XC123887_1.npy']\n",
    "    results = create_annotated_dataframe(all_data)\n",
    "    return results\n",
    "\n",
    "def create_all_clips():\n",
    "    all_data = []\n",
    "    for primary_label in os.listdir(IMAGE_PATH):\n",
    "        directories = os.listdir(IMAGE_PATH + primary_label)\n",
    "        if All_BUT_LAST:\n",
    "            if len(directories) > 1:\n",
    "                directories = directories[:-1]\n",
    "            all_data += [primary_label + '/' + x for x in directories]\n",
    "        else:\n",
    "            all_data += [primary_label + '/' + x for x in directories]\n",
    "    results = create_annotated_dataframe(all_data)\n",
    "    return results\n",
    "\n",
    "def create_annotated_dataframe(all_data):\n",
    "    base_data = {'file_name': [], 'label': []}\n",
    "    for item in all_data:\n",
    "        base_data['file_name'].append(item)\n",
    "        base_data['label'].append(item.split('/')[0])\n",
    "    results = create_encoded_dataframe(base_data)\n",
    "    return results\n",
    "\n",
    "def create_encoded_dataframe(base_data):\n",
    "    results = pd.DataFrame(base_data, columns = ['file_name', 'label'])\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(results['label'])\n",
    "    results['label'] = np.int64(labels)\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def stratified_split(dataset):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset['file_name'].to_numpy(),\n",
    "                                                  dataset['label'].to_numpy(),\n",
    "                                                  test_size=0.25,\n",
    "                                                  stratify=dataset['label'],\n",
    "                                                  random_state=SEED)\n",
    "\n",
    "    train = CustomDataset(x_train, y_train, IMAGE_PATH)\n",
    "    val = CustomDataset(x_val, y_val, IMAGE_PATH)\n",
    "    return train, val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset = create_first_clip() if ONLY_FIRST else create_all_clips()\n",
    "train, val = stratified_split(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "datamodule = ImageClassificationData.from_datasets(train_dataset=train,\n",
    "                                                   val_dataset=val,\n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   )\n",
    "performance_metrics = [torchmetrics.Accuracy(),\n",
    "                      torchmetrics.F1Score(num_classes=len(train.classes), average='macro')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'efficientnet_b0' provided by rwightman/pytorch-image-models (https://github.com/rwightman/pytorch-image-models).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(backbone='efficientnet_b0',\n",
    "                        labels=train.classes,\n",
    "                        metrics=performance_metrics,\n",
    "                        loss_fn=LabelSmoothingCrossEntropy(0.02),\n",
    "                        optimizer=\"AdamW\",\n",
    "                        learning_rate=INIT_LR, )\n",
    "\n",
    "logger = CSVLogger(save_dir='logs/')\n",
    "\n",
    "trainer = flash.Trainer(max_epochs=EPOCHS,\n",
    "                        gpus=torch.cuda.device_count(),\n",
    "                        logger=logger)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | loss_fn       | ModuleDict     | 0     \n",
      "1 | train_metrics | ModuleDict     | 0     \n",
      "2 | val_metrics   | ModuleDict     | 0     \n",
      "3 | test_metrics  | ModuleDict     | 0     \n",
      "4 | adapter       | DefaultAdapter | 4.2 M \n",
      "-------------------------------------------------\n",
      "236 K     Trainable params\n",
      "4.0 M     Non-trainable params\n",
      "4.2 M     Total params\n",
      "16.809    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation sanity check: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caff77ebb9534024a0dcab725afbd8f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd8df81e4d354b6fb193fd9d6bc3253c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] total time taken to train the model: 0.79min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CYBORGX\\anaconda3\\envs\\birdclef\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "trainer.finetune(model,\n",
    "                 datamodule=datamodule,\n",
    "                 strategy='freeze')\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"[INFO] total time taken to train the model: {(endTime - startTime) / 60 :.2f}min\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"../saved-models/Lightning-efficientB0-all-examples.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "display(metrics)\n",
    "del metrics[\"epoch\"]\n",
    "metrics.set_index(\"step\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.figure(figsize=(20, 18))\n",
    "plt.plot(metrics[\"train_labelsmoothingcrossentropy_step\"], label=\"train_loss\")\n",
    "plt.plot(metrics[\"val_labelsmoothingcrossentropy\"], label=\"val_loss\")\n",
    "plt.plot(metrics[\"train_accuracy_step\"], label=\"train_acc\")\n",
    "plt.plot(metrics[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.plot(metrics[\"train_f1score_step\"], label=\"train f1_score\")\n",
    "plt.plot(metrics[\"val_f1score\"], label=\"val f1_score\")\n",
    "plt.title(\"Training Loss, Accuracy and F1 on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy/F1\")\n",
    "plt.legend(loc=\"lower left\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.relplot(data=metrics, kind=\"line\", height=20)\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}